{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972659dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"IMDB_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f733e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"review\",\"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2552d9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "104ced97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8952ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_label = df.sentiment.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daf64380",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.review.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f0dd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c895ed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 13:55:01.190407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-25 13:55:01.190422: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "885fd991",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = tokenizer.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b6e36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_sequence = pad_sequences(encoded_docs, maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90d4712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 32)           3976096   \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 200, 32)          0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50)                16600     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,992,747\n",
      "Trainable params: 3,992,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_length, input_length=200))\n",
    "model.add(SpatialDropout1D(0.25))\n",
    "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c7192e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1250/1250 [==============================] - 114s 91ms/step - loss: 0.2266 - accuracy: 0.9104 - val_loss: 0.3478 - val_accuracy: 0.8768\n",
      "Epoch 2/40\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 0.2184 - accuracy: 0.9141 - val_loss: 0.3228 - val_accuracy: 0.8856\n",
      "Epoch 3/40\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 0.2054 - accuracy: 0.9190 - val_loss: 0.3189 - val_accuracy: 0.8854\n",
      "Epoch 4/40\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 0.2033 - accuracy: 0.9208 - val_loss: 0.3462 - val_accuracy: 0.8832\n",
      "Epoch 5/40\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 0.1933 - accuracy: 0.9253 - val_loss: 0.2883 - val_accuracy: 0.8898\n",
      "Epoch 6/40\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 0.1907 - accuracy: 0.9265 - val_loss: 0.2943 - val_accuracy: 0.8903\n",
      "Epoch 7/40\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 0.1775 - accuracy: 0.9301 - val_loss: 0.3089 - val_accuracy: 0.8882\n",
      "Epoch 8/40\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 0.1760 - accuracy: 0.9314 - val_loss: 0.3432 - val_accuracy: 0.8893\n",
      "Epoch 9/40\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 0.1651 - accuracy: 0.9351 - val_loss: 0.3678 - val_accuracy: 0.8871\n",
      "Epoch 10/40\n",
      "1250/1250 [==============================] - 107s 86ms/step - loss: 0.1665 - accuracy: 0.9347 - val_loss: 0.3474 - val_accuracy: 0.8893\n",
      "Epoch 11/40\n",
      "1250/1250 [==============================] - 108s 87ms/step - loss: 0.1579 - accuracy: 0.9389 - val_loss: 0.3400 - val_accuracy: 0.8917\n",
      "Epoch 12/40\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 0.1605 - accuracy: 0.9371 - val_loss: 0.3342 - val_accuracy: 0.8887\n",
      "Epoch 13/40\n",
      "1250/1250 [==============================] - 114s 91ms/step - loss: 0.1470 - accuracy: 0.9446 - val_loss: 0.3538 - val_accuracy: 0.8901\n",
      "Epoch 14/40\n",
      "1250/1250 [==============================] - 109s 88ms/step - loss: 0.1455 - accuracy: 0.9451 - val_loss: 0.4107 - val_accuracy: 0.8878\n",
      "Epoch 15/40\n",
      "1250/1250 [==============================] - 115s 92ms/step - loss: 0.1411 - accuracy: 0.9470 - val_loss: 0.3815 - val_accuracy: 0.8917\n",
      "Epoch 16/40\n",
      "1250/1250 [==============================] - 116s 93ms/step - loss: 0.1407 - accuracy: 0.9484 - val_loss: 0.3861 - val_accuracy: 0.8892\n",
      "Epoch 17/40\n",
      "1250/1250 [==============================] - 122s 98ms/step - loss: 0.1399 - accuracy: 0.9459 - val_loss: 0.4155 - val_accuracy: 0.8901\n",
      "Epoch 18/40\n",
      "1250/1250 [==============================] - 120s 96ms/step - loss: 0.1297 - accuracy: 0.9512 - val_loss: 0.3881 - val_accuracy: 0.8905\n",
      "Epoch 19/40\n",
      "1250/1250 [==============================] - 115s 92ms/step - loss: 0.1294 - accuracy: 0.9506 - val_loss: 0.5109 - val_accuracy: 0.8671\n",
      "Epoch 20/40\n",
      "1250/1250 [==============================] - 118s 94ms/step - loss: 0.1286 - accuracy: 0.9508 - val_loss: 0.3986 - val_accuracy: 0.8902\n",
      "Epoch 21/40\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 0.1223 - accuracy: 0.9539 - val_loss: 0.4942 - val_accuracy: 0.8738\n",
      "Epoch 22/40\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 0.1217 - accuracy: 0.9545 - val_loss: 0.4528 - val_accuracy: 0.8902\n",
      "Epoch 23/40\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 0.1171 - accuracy: 0.9563 - val_loss: 0.3848 - val_accuracy: 0.8917\n",
      "Epoch 24/40\n",
      "1250/1250 [==============================] - 107s 86ms/step - loss: 0.1147 - accuracy: 0.9571 - val_loss: 0.4498 - val_accuracy: 0.8857\n",
      "Epoch 25/40\n",
      "1250/1250 [==============================] - 108s 87ms/step - loss: 0.1112 - accuracy: 0.9581 - val_loss: 0.4743 - val_accuracy: 0.8815\n",
      "Epoch 26/40\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 0.1073 - accuracy: 0.9599 - val_loss: 0.4473 - val_accuracy: 0.8888\n",
      "Epoch 27/40\n",
      "1250/1250 [==============================] - 117s 93ms/step - loss: 0.1051 - accuracy: 0.9604 - val_loss: 0.4090 - val_accuracy: 0.8898\n",
      "Epoch 28/40\n",
      "1250/1250 [==============================] - 118s 95ms/step - loss: 0.1063 - accuracy: 0.9600 - val_loss: 0.3956 - val_accuracy: 0.8910\n",
      "Epoch 29/40\n",
      "1250/1250 [==============================] - 129s 103ms/step - loss: 0.1039 - accuracy: 0.9620 - val_loss: 0.4403 - val_accuracy: 0.8899\n",
      "Epoch 30/40\n",
      "1250/1250 [==============================] - 115s 92ms/step - loss: 0.1015 - accuracy: 0.9631 - val_loss: 0.4546 - val_accuracy: 0.8880\n",
      "Epoch 31/40\n",
      "1250/1250 [==============================] - 116s 93ms/step - loss: 0.0984 - accuracy: 0.9636 - val_loss: 0.4560 - val_accuracy: 0.8888\n",
      "Epoch 32/40\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.0954 - accuracy: 0.9653 - val_loss: 0.5366 - val_accuracy: 0.8858\n",
      "Epoch 33/40\n",
      "1250/1250 [==============================] - 115s 92ms/step - loss: 0.0957 - accuracy: 0.9651 - val_loss: 0.4260 - val_accuracy: 0.8907\n",
      "Epoch 34/40\n",
      "1250/1250 [==============================] - 118s 94ms/step - loss: 0.0922 - accuracy: 0.9665 - val_loss: 0.4620 - val_accuracy: 0.8893\n",
      "Epoch 35/40\n",
      "1250/1250 [==============================] - 114s 91ms/step - loss: 0.0901 - accuracy: 0.9674 - val_loss: 0.5149 - val_accuracy: 0.8900\n",
      "Epoch 36/40\n",
      "1250/1250 [==============================] - 116s 93ms/step - loss: 0.0889 - accuracy: 0.9672 - val_loss: 0.4540 - val_accuracy: 0.8919\n",
      "Epoch 37/40\n",
      "1250/1250 [==============================] - 119s 95ms/step - loss: 0.0883 - accuracy: 0.9681 - val_loss: 0.4866 - val_accuracy: 0.8877\n",
      "Epoch 38/40\n",
      "1250/1250 [==============================] - 108s 86ms/step - loss: 0.0872 - accuracy: 0.9679 - val_loss: 0.5258 - val_accuracy: 0.8849\n",
      "Epoch 39/40\n",
      "1250/1250 [==============================] - 108s 86ms/step - loss: 0.0850 - accuracy: 0.9696 - val_loss: 0.4691 - val_accuracy: 0.8860\n",
      "Epoch 40/40\n",
      "1250/1250 [==============================] - 109s 88ms/step - loss: 0.0799 - accuracy: 0.9707 - val_loss: 0.4488 - val_accuracy: 0.8881\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(padded_sequence,sentiment_label[0],validation_split=0.2, epochs=40, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b20bcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 16:19:46.430963: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://90b7d6c9-1599-438f-ae54-2d9f2d0c6a90/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f300bdf41c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "pickle.dump(model, open('imdb_model.sav', 'wb'))\n",
    "pickle.dump(tokenizer, open('imdb_model_tokenizer.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "145d73fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Predicted label:  positive\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('imdb_model.sav', 'rb'))\n",
    "loaded_tokenizer = pickle.load(open('imdb_model_tokenizer.sav', 'rb'))\n",
    "\n",
    "text = [\"This is a Good news\"]\n",
    "\n",
    "tw = loaded_tokenizer.texts_to_sequences(text)\n",
    "tw = pad_sequences(tw,maxlen=200)\n",
    "prediction = int(loaded_model.predict(tw).round().item())\n",
    "print(prediction)\n",
    "print(\"Predicted label: \", sentiment_label[1][prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825b02f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
